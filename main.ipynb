{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50371f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\asus\\anaconda3\\lib\\site-packages (4.52.4)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: torch in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\asus\\anaconda3\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\asus\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from datasets) (2025.5.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\asus\\anaconda3\\lib\\site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from datasets) (0.32.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\anaconda3\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\asus\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\asus\\anaconda3\\lib\\site-packages (from sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: streamlit in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.45.1)\n",
      "Requirement already satisfied: ragas in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.2.15)\n",
      "Requirement already satisfied: langchain in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: openai in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.85.0)\n",
      "Requirement already satisfied: chromadb in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.0.12)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from streamlit) (8.0.4)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from streamlit) (2.0.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from streamlit) (9.4.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from streamlit) (5.29.5)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from streamlit) (4.14.0)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from streamlit) (2.1.6)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from streamlit) (6.3.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ragas) (2.12.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ragas) (0.9.0)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ragas) (0.3.64)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ragas) (0.3.24)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ragas) (0.3.21)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ragas) (1.5.6)\n",
      "Requirement already satisfied: appdirs in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ragas) (1.4.4)\n",
      "Requirement already satisfied: pydantic>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ragas) (2.11.5)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from ragas) (5.6.3)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\asus\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: fastapi==0.115.9 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (0.115.9)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (0.34.3)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (4.8.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (0.55b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (1.34.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (1.73.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (33.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (3.10.18)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (14.0.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from chromadb) (4.24.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from fastapi==0.115.9->chromadb) (0.45.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.42.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\asus\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: certifi in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.25.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\asus\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.26.16)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langchain-core->ragas) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\asus\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\asus\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: sympy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.34.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.34.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.55b1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.55b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.55b1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.55b1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.55b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.55b1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.55b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation==0.55b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.55b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic>=2->ragas) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic>=2->ragas) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic>=2->ragas) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.32.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from datasets->ragas) (0.3.6)\n",
      "Requirement already satisfied: xxhash in c:\\users\\asus\\anaconda3\\lib\\site-packages (from datasets->ragas) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\asus\\anaconda3\\lib\\site-packages (from datasets->ragas) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from datasets->ragas) (2025.5.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\asus\\anaconda3\\lib\\site-packages (from datasets->ragas) (3.8.5)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from datasets->ragas) (0.13.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langchain-community->ragas) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langchain-community->ragas) (2.9.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langchain-community->ragas) (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tiktoken->ragas) (2022.7.9)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp->datasets->ragas) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp->datasets->ragas) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp->datasets->ragas) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp->datasets->ragas) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from aiohttp->datasets->ragas) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (0.9.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.9.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers sentence-transformers faiss-cpu torch pandas numpy\n",
    "!pip install streamlit ragas langchain openai chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d12a427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries and Setup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "from typing import List, Dict, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ebbccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML and NLP\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec6f1c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Search\n",
    "import faiss\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8e4dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf871f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Streamlit components\n",
    "import streamlit as st\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d150989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (2508, 2)\n",
      "Columns: ['text', 'title']\n",
      "\n",
      "First 5 rows:\n",
      "                                                text                  title\n",
      "0     ‚ÄúBe yourself; everyone else is already taken.‚Äù            Oscar Wilde\n",
      "1  ‚ÄúI'm selfish, impatient and a little insecure....         Marilyn Monroe\n",
      "2  ‚ÄúTwo things are infinite: the universe and hum...        Albert Einstein\n",
      "3                   ‚ÄúSo many books, so little time.‚Äù            Frank Zappa\n",
      "4  ‚ÄúA room without books is like a body without a...  Marcus Tullius Cicero\n",
      "\n",
      "Dataset Info:\n",
      "Total quotes: 2508\n",
      "Unique authors: 880\n",
      "Tags available in original dataset\n",
      "Sample tags: [['be-yourself', 'gilbert-perreira', 'honesty', 'inspirational', 'misattributed-oscar-wilde', 'quote-investigator'], ['best', 'life', 'love', 'mistakes', 'out-of-control', 'truth', 'worst'], ['human-nature', 'humor', 'infinity', 'philosophy', 'science', 'stupidity', 'universe']]\n"
     ]
    }
   ],
   "source": [
    "# Data Loading and Exploration\n",
    "\n",
    "# Load dataset from HuggingFace hub\n",
    "df = pd.read_json(\"hf://datasets/Abirate/english_quotes/quotes.jsonl\", lines=True)\n",
    "\n",
    "# Clean and filter out missing or bad values\n",
    "df = df.dropna(subset=[\"quote\", \"author\"])\n",
    "df = df[df[\"quote\"].str.strip() != \"\"]\n",
    "\n",
    "# Rename and keep only what RAG needs: 'title' and 'text'\n",
    "df_rag = df[[\"quote\", \"author\"]].copy()\n",
    "df_rag.columns = [\"text\", \"title\"]  # RAG expects these column names\n",
    "\n",
    "# Save to CSV so we can use it later\n",
    "df_rag.to_csv(\"quotes.csv\", index=False)\n",
    "\n",
    "# Quick preview\n",
    "print(f\"Dataset shape: {df_rag.shape}\")\n",
    "print(f\"Columns: {df_rag.columns.tolist()}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_rag.head())\n",
    "\n",
    "#Basic statistics\n",
    "print(f\"\\nDataset Info:\")\n",
    "print(f\"Total quotes: {len(df_rag)}\")\n",
    "print(f\"Unique authors: {df_rag['title'].nunique()}\")\n",
    "\n",
    "# Also keep original df with tags for additional processing if available\n",
    "if 'tags' in df.columns:\n",
    "    print(f\"Tags available in original dataset\")\n",
    "    df_with_tags = df[[\"quote\", \"author\", \"tags\"]].copy()\n",
    "    print(f\"Sample tags: {df_with_tags['tags'].dropna().head(3).tolist()}\")\n",
    "else:\n",
    "    print(\"No tags column found in dataset\")\n",
    "    df_with_tags = df[[\"quote\", \"author\"]].copy()\n",
    "    df_with_tags['tags'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40b82dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataset shape: (2507, 8)\n",
      "Sample combined text:\n",
      "Be yourself; everyone else is already taken. [AUTHOR] Oscar Wilde\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing and Cleaning\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and preprocess text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # Remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', str(text)).strip()\n",
    "    # Remove special characters but keep basic punctuation\n",
    "    text = re.sub(r'[^\\w\\s\\.,!?;:\\'\"()-]', '', text)\n",
    "    return text\n",
    "\n",
    "def preprocess_quotes_data(df_rag, df_with_tags):\n",
    "    \"\"\"Preprocess the quotes dataset\"\"\"\n",
    "    # Create a copy of the RAG dataframe\n",
    "    df_clean = df_rag.copy()\n",
    "    \n",
    "    # Handle missing values (should be minimal after initial cleaning)\n",
    "    df_clean['text'] = df_clean['text'].fillna('')\n",
    "    df_clean['title'] = df_clean['title'].fillna('Unknown')\n",
    "    \n",
    "    # Clean text fields\n",
    "    df_clean['text_clean'] = df_clean['text'].apply(preprocess_text)\n",
    "    df_clean['title_clean'] = df_clean['title'].apply(preprocess_text)\n",
    "    \n",
    "    # Remove empty quotes\n",
    "    df_clean = df_clean[df_clean['text_clean'] != ''].reset_index(drop=True)\n",
    "    \n",
    "    # Add tags if available from original dataset\n",
    "    if len(df_with_tags) == len(df_clean) and 'tags' in df_with_tags.columns:\n",
    "        df_clean['tags'] = df_with_tags['tags'].fillna('')\n",
    "        # Create combined text for embedding with tags\n",
    "        df_clean['combined_text'] = (\n",
    "            df_clean['text_clean'] + ' [AUTHOR] ' + \n",
    "            df_clean['title_clean'] + ' [TAGS] ' + \n",
    "            df_clean['tags'].astype(str)\n",
    "        )\n",
    "    else:\n",
    "        # Create combined text without tags\n",
    "        df_clean['combined_text'] = (\n",
    "            df_clean['text_clean'] + ' [AUTHOR] ' + \n",
    "            df_clean['title_clean']\n",
    "        )\n",
    "        df_clean['tags'] = ''\n",
    "    \n",
    "    # For compatibility with rest of code, create quote and author columns\n",
    "    df_clean['quote'] = df_clean['text']\n",
    "    df_clean['author'] = df_clean['title']\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Preprocess the data\n",
    "df_processed = preprocess_quotes_data(df_rag, df_with_tags)\n",
    "print(f\"Processed dataset shape: {df_processed.shape}\")\n",
    "print(f\"Sample combined text:\")\n",
    "print(df_processed['combined_text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7cf8b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training examples...\n",
      "Created 5000 training examples\n",
      "Starting fine-tuning...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240879365cab4942846fc540cf7d5cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d647b77fb0f42c39de03f4432e7d922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning completed!\n",
      "Model saved to ./fine_tuned_quotes_model\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning Sentence Transformer Model\n",
    "\n",
    "class QuotesSentenceTransformer:\n",
    "    def __init__(self, base_model='all-MiniLM-L6-v2'):\n",
    "        self.model = SentenceTransformer(base_model)\n",
    "        self.base_model = base_model\n",
    "        \n",
    "    def create_training_examples(self, df, num_examples=1000):\n",
    "        \"\"\"Create training examples for fine-tuning\"\"\"\n",
    "        examples = []\n",
    "        \n",
    "        # Sample data for training\n",
    "        sample_df = df.sample(n=min(num_examples, len(df)), random_state=42)\n",
    "        \n",
    "        for _, row in sample_df.iterrows():\n",
    "            # Create positive examples (query-text pairs)\n",
    "            quote = row.get('text_clean', row.get('quote', ''))\n",
    "            author = row.get('title_clean', row.get('author', ''))\n",
    "            tags = str(row.get('tags', ''))\n",
    "            combined = row['combined_text']\n",
    "            \n",
    "            # Generate different query styles for the same quote\n",
    "            queries = [\n",
    "                f\"quotes by {author}\",\n",
    "                f\"quotes about {tags.split(',')[0] if tags and tags != '' else 'life'}\",\n",
    "                f\"{author} quotes\",\n",
    "                f\"inspirational quotes by {author}\",\n",
    "                quote[:50] + \"...\" if len(quote) > 50 else quote\n",
    "            ]\n",
    "            \n",
    "            for query in queries:\n",
    "                if query.strip() and query.strip() != \"quotes about \":\n",
    "                    examples.append(InputExample(texts=[query, combined], label=1.0))\n",
    "        \n",
    "        return examples\n",
    "    \n",
    "    def fine_tune(self, df, epochs=1, batch_size=16):\n",
    "        \"\"\"Fine-tune the model on quotes data\"\"\"\n",
    "        print(\"Creating training examples...\")\n",
    "        train_examples = self.create_training_examples(df)\n",
    "        print(f\"Created {len(train_examples)} training examples\")\n",
    "        \n",
    "        # Create DataLoader\n",
    "        train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)\n",
    "        \n",
    "        # Define loss function\n",
    "        train_loss = losses.CosineSimilarityLoss(self.model)\n",
    "        \n",
    "        print(\"Starting fine-tuning...\")\n",
    "        # Fine-tune the model\n",
    "        self.model.fit(\n",
    "            train_objectives=[(train_dataloader, train_loss)],\n",
    "            epochs=epochs,\n",
    "            warmup_steps=100,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        \n",
    "        print(\"Fine-tuning completed!\")\n",
    "    \n",
    "    def encode(self, texts):\n",
    "        \"\"\"Encode texts to embeddings\"\"\"\n",
    "        return self.model.encode(texts, show_progress_bar=True)\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        \"\"\"Save the fine-tuned model\"\"\"\n",
    "        self.model.save(path)\n",
    "        print(f\"Model saved to {path}\")\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        \"\"\"Load a fine-tuned model\"\"\"\n",
    "        self.model = SentenceTransformer(path)\n",
    "        print(f\"Model loaded from {path}\")\n",
    "\n",
    "# Initialize and fine-tune the model\n",
    "quotes_model = QuotesSentenceTransformer()\n",
    "\n",
    "# Fine-tune on a subset for demonstration (use more epochs and data for production)\n",
    "quotes_model.fine_tune(df_processed, epochs=1, batch_size=16)\n",
    "\n",
    "# Save the model\n",
    "model_path = \"./fine_tuned_quotes_model\"\n",
    "quotes_model.save_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87c3e600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for all quotes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abd91e7160242398d3cf76a8a4bc9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index created with 2507 quotes\n",
      "Index saved to quotes_index.faiss\n",
      "Data saved to quotes_data.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b625854305334ea3bad2af6d68a5bcbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test search for: 'quotes about hope by Oscar Wilde'\n",
      "Rank 1: ‚ÄúHearts are made to be broken.‚Äù... by Oscar Wilde, (Score: 0.9931)\n",
      "Rank 2: ‚ÄúWho, being loved, is poor?‚Äù... by Oscar Wilde (Score: 0.9930)\n",
      "Rank 3: ‚ÄúA good friend will always stab you in the front.‚Äù... by Oscar Wilde (Score: 0.9927)\n"
     ]
    }
   ],
   "source": [
    "# Vector Indexing with FAISS\n",
    "\n",
    "class QuotesVectorIndex:\n",
    "    def __init__(self, model, df):\n",
    "        self.model = model\n",
    "        self.df = df\n",
    "        self.index = None\n",
    "        self.embeddings = None\n",
    "        \n",
    "    def create_index(self):\n",
    "        \"\"\"Create FAISS index from quotes embeddings\"\"\"\n",
    "        print(\"Generating embeddings for all quotes...\")\n",
    "        \n",
    "        # Generate embeddings for all quotes\n",
    "        texts = self.df['combined_text'].tolist()\n",
    "        self.embeddings = self.model.encode(texts)\n",
    "        \n",
    "        # Create FAISS index\n",
    "        dimension = self.embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatIP(dimension)  # Inner product for cosine similarity\n",
    "        \n",
    "        # Normalize embeddings for cosine similarity\n",
    "        faiss.normalize_L2(self.embeddings)\n",
    "        \n",
    "        # Add embeddings to index\n",
    "        self.index.add(self.embeddings.astype(np.float32))\n",
    "        \n",
    "        print(f\"Index created with {self.index.ntotal} quotes\")\n",
    "        \n",
    "    def search(self, query, top_k=5):\n",
    "        \"\"\"Search for similar quotes\"\"\"\n",
    "        if self.index is None:\n",
    "            raise ValueError(\"Index not created. Call create_index() first.\")\n",
    "        \n",
    "        # Encode query\n",
    "        query_embedding = self.model.encode([query])\n",
    "        faiss.normalize_L2(query_embedding)\n",
    "        \n",
    "        # Search\n",
    "        scores, indices = self.index.search(query_embedding.astype(np.float32), top_k)\n",
    "        \n",
    "        # Get results\n",
    "        results = []\n",
    "        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
    "            if idx != -1:  # Valid result\n",
    "                row = self.df.iloc[idx]\n",
    "                results.append({\n",
    "                    'rank': i + 1,\n",
    "                    'quote': row.get('quote', row.get('text', '')),\n",
    "                    'author': row.get('author', row.get('title', '')),\n",
    "                    'tags': row.get('tags', ''),\n",
    "                    'similarity_score': float(score),\n",
    "                    'index': int(idx)\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save_index(self, index_path, data_path):\n",
    "        \"\"\"Save index and associated data\"\"\"\n",
    "        faiss.write_index(self.index, index_path)\n",
    "        with open(data_path, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'embeddings': self.embeddings,\n",
    "                'df': self.df\n",
    "            }, f)\n",
    "        print(f\"Index saved to {index_path}\")\n",
    "        print(f\"Data saved to {data_path}\")\n",
    "\n",
    "# Create vector index\n",
    "vector_index = QuotesVectorIndex(quotes_model, df_processed)\n",
    "vector_index.create_index()\n",
    "\n",
    "# Save index\n",
    "vector_index.save_index(\"quotes_index.faiss\", \"quotes_data.pkl\")\n",
    "\n",
    "# Test the search\n",
    "test_query = \"quotes about hope by Oscar Wilde\"\n",
    "test_results = vector_index.search(test_query, top_k=3)\n",
    "print(f\"\\nTest search for: '{test_query}'\")\n",
    "for result in test_results:\n",
    "    print(f\"Rank {result['rank']}: {result['quote'][:100]}... by {result['author']} (Score: {result['similarity_score']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df7afcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Initializing RAG Pipeline with LLM...\n",
      " Loading free LLM model for demonstration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM loaded successfully!\n",
      "\n",
      " Testing RAG Pipeline with LLM:\n",
      "\n",
      "==================================================\n",
      " Query: Show me quotes about courage by women authors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd771be8466d4c63bcf0ba55dd700969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Summary:  AI Analysis: 1.\n",
      " Found 3 quotes:\n",
      "   1. \"‚ÄúMy rapier wit hides my inner pain.‚Äù...\" - Cassandra Clare\n",
      "   2. \"‚ÄúA brave man acknowledges the strength of others.‚Äù...\" - Veronica Roth,\n",
      " Response generated with LLM\n",
      "\n",
      "==================================================\n",
      " Query: inspirational quotes about success\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58830333efd64e20bdb18d5f49c752b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Summary:  AI Analysis: 1.\n",
      " Found 3 quotes:\n",
      "   1. \"‚ÄúThe best way to cheer yourself is to try to cheer someone else up.‚Äù...\" - Mark Twain\n",
      "   2. \"‚ÄúSuccess is stumbling from failure to failure with no loss of enthusiasm.‚Äù...\" - Winston S. Churchill\n",
      " Response generated with LLM\n",
      "\n",
      "==================================================\n",
      " Query: quotes about love by Shakespeare\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb436f06fa8c4e61ae798cff7563c5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Summary:  AI Analysis: 1.\n",
      " Found 3 quotes:\n",
      "   1. \"‚ÄúStars, hide your fires; Let not light see my black and deep desires.‚Äù...\" - William Shakespeare,\n",
      "   2. \"‚ÄúWords are easy, like the wind; Faithful friends are hard to find.‚Äù...\" - William Shakespeare,\n",
      " Response generated with LLM\n",
      "\n",
      "==================================================\n",
      " Query: motivational quotes for difficult times\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647966f210fc4f2cb53e8e123e40f703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Summary:  AI Analysis: 1.\n",
      " Found 3 quotes:\n",
      "   1. \"‚ÄúCourage isn't having the strength to go on - it is going on when you don't have...\" - Napoleon Bonaparte\n",
      "   2. \"‚ÄúThe most painful thing is losing yourself in the process of loving someone too ...\" - Ernest Hemingway,\n",
      " Response generated with LLM\n",
      "\n",
      " RAG Pipeline Setup Complete!\n",
      " LLM Status: Active\n"
     ]
    }
   ],
   "source": [
    "# RAG Pipeline Implementation with LLM\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Install required packages for LLM\"\"\"\n",
    "    packages = ['transformers', 'torch', 'accelerate']\n",
    "    for package in packages:\n",
    "        try:\n",
    "            __import__(package)\n",
    "            print(f\" {package} already installed\")\n",
    "        except ImportError:\n",
    "            print(f\" Installing {package}...\")\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "\n",
    "\n",
    "# Import required libraries\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class RAGQuotesPipeline:\n",
    "    def __init__(self, vector_index, use_llm=True):\n",
    "        self.vector_index = vector_index\n",
    "        self.use_llm = use_llm\n",
    "        self.llm = None\n",
    "        \n",
    "        # Initialize free LLM\n",
    "        if use_llm:\n",
    "            self._load_llm()\n",
    "        \n",
    "    def _load_llm(self):\n",
    "        \"\"\"Load the free LLM model\"\"\"\n",
    "        print(\" Loading free LLM model for demonstration...\")\n",
    "        try:\n",
    "            # Use a lightweight text generation model\n",
    "            self.llm = pipeline(\n",
    "                \"text-generation\",\n",
    "                model=\"distilgpt2\",  # Lightweight and fast\n",
    "                tokenizer=\"distilgpt2\",\n",
    "                device=0 if torch.cuda.is_available() else -1,\n",
    "                max_length=150,\n",
    "                do_sample=True,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            print(\"‚úÖ LLM loaded successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading LLM: {e}\")\n",
    "            print(\"üìù Falling back to template-based responses\")\n",
    "            self.llm = None\n",
    "            self.use_llm = False\n",
    "    \n",
    "    def retrieve_quotes(self, query, top_k=5):\n",
    "        \"\"\"Retrieve relevant quotes for a query\"\"\"\n",
    "        return self.vector_index.search(query, top_k)\n",
    "    \n",
    "    def generate_response_simple(self, query, retrieved_quotes):\n",
    "        \"\"\"Generate response using simple template (no external LLM needed)\"\"\"\n",
    "        if not retrieved_quotes:\n",
    "            return {\n",
    "                'query': query,\n",
    "                'summary': 'No relevant quotes found for your query.',\n",
    "                'quotes': [],\n",
    "                'total_found': 0,\n",
    "                'llm_generated': False\n",
    "            }\n",
    "        \n",
    "        # Create summary\n",
    "        authors = list(set([q['author'] for q in retrieved_quotes if q['author'] != 'Unknown']))\n",
    "        tags = []\n",
    "        for q in retrieved_quotes:\n",
    "            if q['tags']:\n",
    "                tags.extend(str(q['tags']).split(','))\n",
    "        \n",
    "        unique_tags = list(set([tag.strip() for tag in tags if tag.strip()]))[:5]\n",
    "        \n",
    "        summary = f\"Found {len(retrieved_quotes)} relevant quotes\"\n",
    "        if authors:\n",
    "            summary += f\" from authors including {', '.join(authors[:3])}\"\n",
    "        if unique_tags:\n",
    "            summary += f\" related to themes like {', '.join(unique_tags[:3])}\"\n",
    "        \n",
    "        return {\n",
    "            'query': query,\n",
    "            'summary': summary,\n",
    "            'quotes': retrieved_quotes,\n",
    "            'total_found': len(retrieved_quotes),\n",
    "            'authors': authors,\n",
    "            'themes': unique_tags,\n",
    "            'llm_generated': False\n",
    "        }\n",
    "    \n",
    "    def generate_response_with_llm(self, query, retrieved_quotes):\n",
    "        \"\"\"Generate response using free LLM\"\"\"\n",
    "        if not self.llm or not retrieved_quotes:\n",
    "            return self.generate_response_simple(query, retrieved_quotes)\n",
    "        \n",
    "        try:\n",
    "            # Get basic info\n",
    "            authors = list(set([q['author'] for q in retrieved_quotes if q['author'] != 'Unknown']))\n",
    "            \n",
    "            # Prepare context for LLM (keep it concise)\n",
    "            context = f\"Query: {query}\\n\\nTop quotes:\\n\"\n",
    "            for i, quote in enumerate(retrieved_quotes[:2], 1):  # Only use top 2 quotes\n",
    "                context += f\"{i}. \\\"{quote['quote'][:100]}...\\\" - {quote['author']}\\n\"\n",
    "            \n",
    "            # Create a focused prompt\n",
    "            prompt = f\"\"\"Analyze these quotes about \"{query}\":\n",
    "\n",
    "{context}\n",
    "\n",
    "Key insights:\"\"\"\n",
    "            \n",
    "            # Generate response with LLM\n",
    "            response = self.llm(\n",
    "                prompt,\n",
    "                max_new_tokens=80,\n",
    "                num_return_sequences=1,\n",
    "                pad_token_id=self.llm.tokenizer.eos_token_id,\n",
    "                truncation=True\n",
    "            )\n",
    "            \n",
    "            # Extract generated text\n",
    "            generated_text = response[0]['generated_text']\n",
    "            llm_analysis = generated_text[len(prompt):].strip()\n",
    "            \n",
    "            # Clean up the response\n",
    "            if llm_analysis:\n",
    "                # Take first complete sentence\n",
    "                sentences = llm_analysis.split('.')\n",
    "                if len(sentences) > 1:\n",
    "                    llm_analysis = sentences[0] + '.'\n",
    "                else:\n",
    "                    llm_analysis = llm_analysis[:100] + \"...\"\n",
    "            else:\n",
    "                llm_analysis = \"These quotes provide valuable insights on your query.\"\n",
    "            \n",
    "            # Combine with retrieved data\n",
    "            return {\n",
    "                'query': query,\n",
    "                'summary': f\" AI Analysis: {llm_analysis}\",\n",
    "                'quotes': retrieved_quotes,\n",
    "                'total_found': len(retrieved_quotes),\n",
    "                'authors': authors,\n",
    "                'themes': [],\n",
    "                'llm_generated': True\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è LLM generation error: {e}\")\n",
    "            return self.generate_response_simple(query, retrieved_quotes)\n",
    "    \n",
    "    def search_and_generate(self, query, top_k=5, use_llm=None):\n",
    "        \"\"\"Complete RAG pipeline: retrieve and generate\"\"\"\n",
    "        # Use instance setting if not specified\n",
    "        if use_llm is None:\n",
    "            use_llm = self.use_llm\n",
    "            \n",
    "        # Retrieve\n",
    "        retrieved_quotes = self.retrieve_quotes(query, top_k)\n",
    "        \n",
    "        # Generate\n",
    "        if use_llm and self.llm:\n",
    "            response = self.generate_response_with_llm(query, retrieved_quotes)\n",
    "        else:\n",
    "            response = self.generate_response_simple(query, retrieved_quotes)\n",
    "        \n",
    "        return response\n",
    "\n",
    "# Initialize RAG pipeline with LLM\n",
    "print(\"üîß Initializing RAG Pipeline with LLM...\")\n",
    "rag_pipeline = RAGQuotesPipeline(vector_index, use_llm=True)\n",
    "\n",
    "# Test the complete pipeline\n",
    "test_queries = [\n",
    "    \"Show me quotes about courage by women authors\",\n",
    "    \"inspirational quotes about success\",\n",
    "    \"quotes about love by Shakespeare\",\n",
    "    \"motivational quotes for difficult times\"\n",
    "]\n",
    "\n",
    "print(\"\\n Testing RAG Pipeline with LLM:\")\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\" Query: {query}\")\n",
    "    \n",
    "    # Test with LLM\n",
    "    result = rag_pipeline.search_and_generate(query, top_k=3, use_llm=True)\n",
    "    print(f\" Summary: {result['summary']}\")\n",
    "    print(f\" Found {result['total_found']} quotes:\")\n",
    "    for i, quote in enumerate(result['quotes'][:2], 1):\n",
    "        print(f\"   {i}. \\\"{quote['quote'][:80]}...\\\" - {quote['author']}\")\n",
    "    \n",
    "    if result['llm_generated']:\n",
    "        print(\" Response generated with LLM\")\n",
    "    else:\n",
    "        print(\" Response generated with template\")\n",
    "\n",
    "print(f\"\\n RAG Pipeline Setup Complete!\")\n",
    "print(f\" LLM Status: {'Active' if rag_pipeline.llm else 'Inactive'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f2aa932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating evaluation dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5c7bb44b0e45c7a06b4a0bf9b29bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb5f9d57db34bd38324a98408138880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683ccd7ded12487b94388cae58780e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae67a5abe283430e92c9aadeeacbaf53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f88831136224e14a3615c80000cf05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9dcafb922f54d39bb49ec040fa0e1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df81bc00b914cdfb150a3704bb53bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3f2468268c4fe5af0a817e36b38681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fa56f2e3e5423fa684290a045830b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26fbca97a634ab78a04da4e9a6cdbb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 10 evaluation samples\n",
      "\n",
      "Sample evaluation data:\n",
      "Question: quotes about love\n",
      "Answer:  AI Analysis: 2.\n",
      "Contexts: 3 contexts\n",
      "Ground Truth: Relevant quotes about love\n",
      "\n",
      "Evaluating RAG Pipeline...\n",
      "Evaluation Results:\n",
      "context_relevance: 0.202\n",
      "answer_quality: 0.150\n",
      "retrieval_accuracy: 1.000\n",
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8504\n",
      "  Network URL: http://192.168.1.4:8504\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 21:13:45.829 Examining the path of torch.classes raised:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\streamlit\\web\\bootstrap.py\", line 347, in run\n",
      "    if asyncio.get_running_loop().is_running():\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: no running event loop\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\streamlit\\watcher\\local_sources_watcher.py\", line 217, in get_module_paths\n",
      "    potential_paths = extract_paths(module)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\streamlit\\watcher\\local_sources_watcher.py\", line 210, in <lambda>\n",
      "    lambda m: list(m.__path__._path),\n",
      "                   ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\torch\\_classes.py\", line 13, in __getattr__\n",
      "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
      "forrtl: error (200): program aborting due to window-CLOSE event\n",
      "Image              PC                Routine            Line        Source             \n",
      "libifcoremd.dll    00007FFB13DADF54  Unknown               Unknown  Unknown\n",
      "KERNELBASE.dll     00007FFB88C34387  Unknown               Unknown  Unknown\n",
      "KERNEL32.DLL       00007FFB8AEA259D  Unknown               Unknown  Unknown\n",
      "ntdll.dll          00007FFB8BA2AF78  Unknown               Unknown  Unknown\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8503\n",
      "  Network URL: http://192.168.1.4:8503\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 21:10:20.191 Examining the path of torch.classes raised:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\streamlit\\web\\bootstrap.py\", line 347, in run\n",
      "    if asyncio.get_running_loop().is_running():\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: no running event loop\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\streamlit\\watcher\\local_sources_watcher.py\", line 217, in get_module_paths\n",
      "    potential_paths = extract_paths(module)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\streamlit\\watcher\\local_sources_watcher.py\", line 210, in <lambda>\n",
      "    lambda m: list(m.__path__._path),\n",
      "                   ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\torch\\_classes.py\", line 13, in __getattr__\n",
      "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
      "forrtl: error (200): program aborting due to window-CLOSE event\n",
      "Image              PC                Routine            Line        Source             \n",
      "libifcoremd.dll    00007FFB13DADF54  Unknown               Unknown  Unknown\n",
      "KERNELBASE.dll     00007FFB88C34387  Unknown               Unknown  Unknown\n",
      "KERNEL32.DLL       00007FFB8AEA259D  Unknown               Unknown  Unknown\n",
      "ntdll.dll          00007FFB8BA2AF78  Unknown               Unknown  Unknown\n"
     ]
    }
   ],
   "source": [
    "# RAG Evaluation using RAGAS\n",
    "\n",
    "def create_evaluation_dataset(rag_pipeline, num_samples=20):\n",
    "    \"\"\"Create evaluation dataset for RAGAS\"\"\"\n",
    "    \n",
    "    # Sample evaluation queries\n",
    "    eval_queries = [\n",
    "        \"quotes about love\",\n",
    "        \"inspirational quotes by Maya Angelou\",\n",
    "        \"quotes about success and hard work\",\n",
    "        \"funny quotes about life\",\n",
    "        \"quotes about friendship\",\n",
    "        \"motivational quotes for students\",\n",
    "        \"quotes about happiness\",\n",
    "        \"quotes by Albert Einstein\",\n",
    "        \"quotes about courage and bravery\",\n",
    "        \"quotes about change and growth\",\n",
    "        \"quotes about leadership\",\n",
    "        \"quotes about dreams and aspirations\",\n",
    "        \"quotes about time and life\",\n",
    "        \"quotes about family\",\n",
    "        \"quotes about wisdom\",\n",
    "        \"quotes by Shakespeare\",\n",
    "        \"quotes about perseverance\",\n",
    "        \"quotes about learning\",\n",
    "        \"quotes about kindness\",\n",
    "        \"quotes about hope and faith\"\n",
    "    ]\n",
    "    \n",
    "    evaluation_data = []\n",
    "    \n",
    "    for query in eval_queries[:num_samples]:\n",
    "        try:\n",
    "            # Get RAG response\n",
    "            result = rag_pipeline.search_and_generate(query, top_k=3)\n",
    "            \n",
    "            # Create contexts from retrieved quotes\n",
    "            contexts = [f\"Quote: {q['quote']} - Author: {q['author']} - Tags: {q['tags']}\" \n",
    "                       for q in result['quotes']]\n",
    "            \n",
    "            # Create ground truth (simplified)\n",
    "            ground_truth = f\"Relevant quotes about {query.replace('quotes about ', '').replace('quotes by ', '')}\"\n",
    "            \n",
    "            evaluation_data.append({\n",
    "                'question': query,\n",
    "                'contexts': contexts,\n",
    "                'answer': result['summary'],\n",
    "                'ground_truth': ground_truth\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing query '{query}': {e}\")\n",
    "            continue\n",
    "    \n",
    "    return evaluation_data\n",
    "\n",
    "# Create evaluation dataset\n",
    "print(\"Creating evaluation dataset...\")\n",
    "eval_data = create_evaluation_dataset(rag_pipeline, num_samples=10)\n",
    "print(f\"Created {len(eval_data)} evaluation samples\")\n",
    "\n",
    "# Display sample evaluation data\n",
    "print(\"\\nSample evaluation data:\")\n",
    "if eval_data:\n",
    "    sample = eval_data[0]\n",
    "    print(f\"Question: {sample['question']}\")\n",
    "    print(f\"Answer: {sample['answer']}\")\n",
    "    print(f\"Contexts: {len(sample['contexts'])} contexts\")\n",
    "    print(f\"Ground Truth: {sample['ground_truth']}\")\n",
    "\n",
    "# Convert to RAGAS format (simplified evaluation)\n",
    "def evaluate_rag_simple(eval_data):\n",
    "    \"\"\"Simple RAG evaluation without external APIs\"\"\"\n",
    "    scores = {\n",
    "        'context_relevance': [],\n",
    "        'answer_quality': [],\n",
    "        'retrieval_accuracy': []\n",
    "    }\n",
    "    \n",
    "    for item in eval_data:\n",
    "        # Simple heuristic scoring\n",
    "        contexts = item['contexts']\n",
    "        answer = item['answer']\n",
    "        question = item['question']\n",
    "        \n",
    "        # Context relevance (check if contexts contain relevant keywords)\n",
    "        question_words = set(question.lower().split())\n",
    "        context_words = set(' '.join(contexts).lower().split())\n",
    "        relevance_score = len(question_words.intersection(context_words)) / len(question_words)\n",
    "        scores['context_relevance'].append(min(relevance_score, 1.0))\n",
    "        \n",
    "        # Answer quality (length and information content)\n",
    "        answer_quality = min(len(answer.split()) / 20, 1.0)  # Normalize by expected length\n",
    "        scores['answer_quality'].append(answer_quality)\n",
    "        \n",
    "        # Retrieval accuracy (number of contexts found)\n",
    "        retrieval_accuracy = min(len(contexts) / 3, 1.0)  # Expecting 3 contexts\n",
    "        scores['retrieval_accuracy'].append(retrieval_accuracy)\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_scores = {metric: np.mean(scores[metric]) for metric in scores}\n",
    "    return avg_scores\n",
    "\n",
    "# Evaluate RAG performance\n",
    "print(\"\\nEvaluating RAG Pipeline...\")\n",
    "evaluation_results = evaluate_rag_simple(eval_data)\n",
    "print(\"Evaluation Results:\")\n",
    "for metric, score in evaluation_results.items():\n",
    "    print(f\"{metric}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98956d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM dependencies available\n",
      "üöÄ Initializing Quotes RAG Application for Jupyter Notebook\n",
      "============================================================\n",
      "üéâ Quotes RAG Application loaded successfully!\n",
      "üìñ Run info() for detailed information\n",
      "üöÄ Run setup() to get started\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Retrieval Augmented Generation for English Quotes with AI Enhancement\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try to import LLM dependencies\n",
    "try:\n",
    "    from transformers import pipeline\n",
    "    import torch\n",
    "    LLM_AVAILABLE = True\n",
    "    print(\" LLM dependencies available\")\n",
    "except ImportError:\n",
    "    LLM_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è LLM dependencies not available. Install with: pip install transformers torch\")\n",
    "\n",
    "class JupyterRAGPipeline:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.index = None\n",
    "        self.df = None\n",
    "        self.llm = None\n",
    "        self.loaded = False\n",
    "    \n",
    "    def load_model_and_index(self):\n",
    "        \"\"\"Load the fine-tuned model and vector index\"\"\"\n",
    "        try:\n",
    "            print(\"üîÑ Loading model and index...\")\n",
    "            \n",
    "            # Load model\n",
    "            self.model = SentenceTransformer(\"./fine_tuned_quotes_model\")\n",
    "            print(\"‚úÖ Model loaded\")\n",
    "            \n",
    "            # Load FAISS index\n",
    "            self.index = faiss.read_index(\"quotes_index.faiss\")\n",
    "            print(\"‚úÖ FAISS index loaded\")\n",
    "            \n",
    "            # Load data\n",
    "            with open(\"quotes_data.pkl\", \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "            self.df = data['df']\n",
    "            print(\"‚úÖ Data loaded\")\n",
    "            \n",
    "            self.loaded = True\n",
    "            print(f\"üìä Dataset contains {len(self.df)} quotes\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading model and index: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def load_llm_model(self):\n",
    "        \"\"\"Load the free LLM model\"\"\"\n",
    "        if not LLM_AVAILABLE:\n",
    "            print(\"‚ö†Ô∏è LLM not available\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            print(\"ü§ñ Loading AI model... This may take a moment.\")\n",
    "            self.llm = pipeline(\n",
    "                \"text-generation\",\n",
    "                model=\"distilgpt2\",\n",
    "                tokenizer=\"distilgpt2\",\n",
    "                device=0 if torch.cuda.is_available() else -1,\n",
    "                max_length=150,\n",
    "                do_sample=True,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            print(\" AI model loaded successfully!\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not load AI model: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def search_quotes(self, query, top_k=5):\n",
    "        \"\"\"Search for quotes using the RAG pipeline\"\"\"\n",
    "        if not self.loaded:\n",
    "            print(\"‚ùå Model not loaded. Please run load_model_and_index() first.\")\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Encode query\n",
    "            query_embedding = self.model.encode([query])\n",
    "            faiss.normalize_L2(query_embedding)\n",
    "            \n",
    "            # Search\n",
    "            scores, indices = self.index.search(query_embedding.astype(np.float32), top_k)\n",
    "            \n",
    "            # Get results\n",
    "            results = []\n",
    "            for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
    "                if idx != -1:\n",
    "                    row = self.df.iloc[idx]\n",
    "                    results.append({\n",
    "                        'rank': i + 1,\n",
    "                        'quote': row.get('quote', row.get('text', '')),\n",
    "                        'author': row.get('author', row.get('title', '')),\n",
    "                        'tags': row.get('tags', ''),\n",
    "                        'similarity_score': float(score),\n",
    "                        'index': int(idx)\n",
    "                    })\n",
    "            \n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Search error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def generate_response_simple(self, query, results):\n",
    "        \"\"\"Generate a structured response without LLM\"\"\"\n",
    "        if not results:\n",
    "            return {\n",
    "                'query': query,\n",
    "                'summary': 'No relevant quotes found for your query.',\n",
    "                'quotes': [],\n",
    "                'total_found': 0,\n",
    "                'authors': [],\n",
    "                'themes': [],\n",
    "                'llm_generated': False\n",
    "            }\n",
    "        \n",
    "        # Extract information\n",
    "        authors = list(set([r['author'] for r in results if r['author'] != 'Unknown']))\n",
    "        tags = []\n",
    "        for r in results:\n",
    "            if r['tags']:\n",
    "                tags.extend(str(r['tags']).split(','))\n",
    "        \n",
    "        unique_tags = list(set([tag.strip() for tag in tags if tag.strip()]))[:5]\n",
    "        \n",
    "        # Generate summary\n",
    "        summary = f\"Found {len(results)} relevant quotes\"\n",
    "        if authors:\n",
    "            summary += f\" from authors including {', '.join(authors[:3])}\"\n",
    "        if unique_tags:\n",
    "            summary += f\" related to themes like {', '.join(unique_tags[:3])}\"\n",
    "        \n",
    "        return {\n",
    "            'query': query,\n",
    "            'summary': summary,\n",
    "            'quotes': results,\n",
    "            'total_found': len(results),\n",
    "            'authors': authors,\n",
    "            'themes': unique_tags,\n",
    "            'llm_generated': False\n",
    "        }\n",
    "    \n",
    "    def generate_response_with_llm(self, query, results):\n",
    "        \"\"\"Generate response using LLM\"\"\"\n",
    "        if not self.llm or not results:\n",
    "            return self.generate_response_simple(query, results)\n",
    "        \n",
    "        try:\n",
    "            # Get basic info\n",
    "            authors = list(set([r['author'] for r in results if r['author'] != 'Unknown']))\n",
    "            \n",
    "            # Prepare context for LLM (keep it concise)\n",
    "            context = f\"Query: {query}\\n\\nTop quotes:\\n\"\n",
    "            for i, quote in enumerate(results[:2], 1):  # Only use top 2 quotes\n",
    "                quote_text = quote['quote'][:100] + \"...\" if len(quote['quote']) > 100 else quote['quote']\n",
    "                context += f\"{i}. \\\"{quote_text}\\\" - {quote['author']}\\n\"\n",
    "            \n",
    "            # Create a focused prompt\n",
    "            prompt = f\"\"\"Analyze these quotes about \"{query}\":\n",
    "\n",
    "{context}\n",
    "\n",
    "Key insights:\"\"\"\n",
    "            \n",
    "            # Generate response with LLM\n",
    "            print(\" AI is analyzing the quotes...\")\n",
    "            response = self.llm(\n",
    "                prompt,\n",
    "                max_new_tokens=60,\n",
    "                num_return_sequences=1,\n",
    "                pad_token_id=self.llm.tokenizer.eos_token_id,\n",
    "                truncation=True\n",
    "            )\n",
    "            \n",
    "            # Extract generated text\n",
    "            generated_text = response[0]['generated_text']\n",
    "            llm_analysis = generated_text[len(prompt):].strip()\n",
    "            \n",
    "            # Clean up the response\n",
    "            if llm_analysis:\n",
    "                # Take first complete sentence or limit length\n",
    "                sentences = llm_analysis.split('.')\n",
    "                if len(sentences) > 1 and len(sentences[0]) > 10:\n",
    "                    llm_analysis = sentences[0] + '.'\n",
    "                else:\n",
    "                    llm_analysis = llm_analysis[:150] + \"...\" if len(llm_analysis) > 150 else llm_analysis\n",
    "            else:\n",
    "                llm_analysis = \"These quotes provide valuable insights related to your query.\"\n",
    "            \n",
    "            # Extract tags for themes\n",
    "            tags = []\n",
    "            for r in results:\n",
    "                if r['tags']:\n",
    "                    tags.extend(str(r['tags']).split(','))\n",
    "            unique_tags = list(set([tag.strip() for tag in tags if tag.strip()]))[:5]\n",
    "            \n",
    "            return {\n",
    "                'query': query,\n",
    "                'summary': f\" AI Analysis: {llm_analysis}\",\n",
    "                'quotes': results,\n",
    "                'total_found': len(results),\n",
    "                'authors': authors,\n",
    "                'themes': unique_tags,\n",
    "                'llm_generated': True\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è AI analysis error: {e}\")\n",
    "            return self.generate_response_simple(query, results)\n",
    "    \n",
    "    def search_and_generate(self, query, top_k=5, use_llm=False):\n",
    "        \"\"\"Complete RAG pipeline: retrieve and generate\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Retrieve quotes\n",
    "        results = self.search_quotes(query, top_k)\n",
    "        \n",
    "        # Generate response\n",
    "        if use_llm and self.llm:\n",
    "            response = self.generate_response_with_llm(query, results)\n",
    "        else:\n",
    "            response = self.generate_response_simple(query, results)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        response['search_time'] = end_time - start_time\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def display_results(self, response, show_scores=True, show_json=False):\n",
    "        \"\"\"Display search results in a formatted way\"\"\"\n",
    "        query = response['query']\n",
    "        \n",
    "        # Header\n",
    "        display(HTML(f\"\"\"\n",
    "        <div style=\"border-left: 4px solid #2196F3; padding-left: 20px; margin: 20px 0;\">\n",
    "            <h2>üìö Search Results for: \"{query}\"</h2>\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "        \n",
    "        # Summary\n",
    "        if response.get('llm_generated'):\n",
    "            display(HTML(f\"\"\"\n",
    "            <div style=\"background-color: #e3f2fd; padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
    "                <h3> AI Analysis</h3>\n",
    "                <p>{response['summary']}</p>\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "        else:\n",
    "            display(HTML(f\"\"\"\n",
    "            <div style=\"background-color: #f5f5f5; padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
    "                <h3>üìä Search Summary</h3>\n",
    "                <p>{response['summary']}</p>\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "        \n",
    "        # Metrics\n",
    "        display(HTML(f\"\"\"\n",
    "        <div style=\"display: flex; gap: 20px; margin: 20px 0;\">\n",
    "            <div style=\"background-color: #e8f5e8; padding: 10px; border-radius: 5px; text-align: center;\">\n",
    "                <strong>Total Found</strong><br>{response['total_found']}\n",
    "            </div>\n",
    "            <div style=\"background-color: #fff3e0; padding: 10px; border-radius: 5px; text-align: center;\">\n",
    "                <strong>Authors</strong><br>{len(response['authors'])}\n",
    "            </div>\n",
    "            <div style=\"background-color: #f3e5f5; padding: 10px; border-radius: 5px; text-align: center;\">\n",
    "                <strong>Themes</strong><br>{len(response['themes'])}\n",
    "            </div>\n",
    "            <div style=\"background-color: #e0f2f1; padding: 10px; border-radius: 5px; text-align: center;\">\n",
    "                <strong>Search Time</strong><br>{response.get('search_time', 0):.2f}s\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "        \n",
    "        # Display quotes\n",
    "        if response['quotes']:\n",
    "            display(HTML(\"<h3>üìö Found Quotes</h3>\"))\n",
    "            \n",
    "            for i, quote_data in enumerate(response['quotes']):\n",
    "                score_display = f\" (Relevance: {quote_data['similarity_score']:.4f})\" if show_scores else \"\"\n",
    "                \n",
    "                display(HTML(f\"\"\"\n",
    "                <div style=\"border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 8px; background-color: #fafafa;\">\n",
    "                    <h4>üìù Quote {i+1}: {quote_data['author']}{score_display}</h4>\n",
    "                    <blockquote style=\"font-style: italic; margin: 10px 0; padding: 10px; border-left: 3px solid #2196F3;\">\n",
    "                        \"{quote_data['quote']}\"\n",
    "                    </blockquote>\n",
    "                    <p><strong>üë§ Author:</strong> {quote_data['author']}</p>\n",
    "                    {f\"<p><strong>üè∑Ô∏è Tags:</strong> {quote_data['tags']}</p>\" if quote_data['tags'] else \"\"}\n",
    "                </div>\n",
    "                \"\"\"))\n",
    "            \n",
    "            # Additional insights\n",
    "            if response['authors'] or response['themes']:\n",
    "                display(HTML(\"<h3>üìä Insights</h3>\"))\n",
    "                \n",
    "                insights_html = \"<div style='display: flex; gap: 30px;'>\"\n",
    "                \n",
    "                if response['authors']:\n",
    "                    authors_list = \"<br>\".join([f\"‚Ä¢ {author}\" for author in response['authors'][:5]])\n",
    "                    insights_html += f\"\"\"\n",
    "                    <div style=\"flex: 1;\">\n",
    "                        <h4>Top Authors:</h4>\n",
    "                        <div>{authors_list}</div>\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "                \n",
    "                if response['themes']:\n",
    "                    themes_list = \"<br>\".join([f\"‚Ä¢ {theme}\" for theme in response['themes'][:5]])\n",
    "                    insights_html += f\"\"\"\n",
    "                    <div style=\"flex: 1;\">\n",
    "                        <h4>Related Themes:</h4>\n",
    "                        <div>{themes_list}</div>\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "                \n",
    "                insights_html += \"</div>\"\n",
    "                display(HTML(insights_html))\n",
    "        \n",
    "        else:\n",
    "            display(HTML(\"\"\"\n",
    "            <div style=\"background-color: #fff3cd; padding: 15px; border-radius: 8px; margin: 10px 0;\">\n",
    "                <p><strong>‚ö†Ô∏è No quotes found for your search query.</strong> Try different keywords!</p>\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "        \n",
    "        # JSON Response (optional)\n",
    "        if show_json:\n",
    "            display(HTML(\"<h3>üîß JSON Response</h3>\"))\n",
    "            display(response)\n",
    "\n",
    "# Initialize the RAG pipeline\n",
    "print(\"üöÄ Initializing Quotes RAG Application for Jupyter Notebook\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "rag = JupyterRAGPipeline()\n",
    "\n",
    "# Example usage functions\n",
    "def setup():\n",
    "    \"\"\"Setup function to load all models and data\"\"\"\n",
    "    print(\"üì¶ Setting up Quotes RAG Application...\")\n",
    "    \n",
    "    # Load main model and index\n",
    "    if not rag.load_model_and_index():\n",
    "        return False\n",
    "    \n",
    "    # Try to load LLM\n",
    "    if LLM_AVAILABLE:\n",
    "        rag.load_llm_model()\n",
    "    \n",
    "    print(\"\\n‚úÖ Setup complete! Ready to search quotes.\")\n",
    "    print(\"\\nüìù Example usage:\")\n",
    "    print(\"  search('quotes about hope')\")\n",
    "    print(\"  search_with_ai('inspirational quotes about success')\")\n",
    "    print(\"  explore_examples()\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def search(query, top_k=5, show_scores=True, show_json=False):\n",
    "    \"\"\"Search for quotes without AI analysis\"\"\"\n",
    "    if not rag.loaded:\n",
    "        print(\"‚ùå Please run setup() first to load the models.\")\n",
    "        return None\n",
    "    \n",
    "    response = rag.search_and_generate(query, top_k, use_llm=False)\n",
    "    rag.display_results(response, show_scores, show_json)\n",
    "    return response\n",
    "\n",
    "def search_with_ai(query, top_k=5, show_scores=True, show_json=False):\n",
    "    \"\"\"Search for quotes with AI analysis\"\"\"\n",
    "    if not rag.loaded:\n",
    "        print(\"‚ùå Please run setup() first to load the models.\")\n",
    "        return None\n",
    "    \n",
    "    if not rag.llm:\n",
    "        print(\"‚ö†Ô∏è AI model not available. Using standard search instead.\")\n",
    "        return search(query, top_k, show_scores, show_json)\n",
    "    \n",
    "    response = rag.search_and_generate(query, top_k, use_llm=True)\n",
    "    rag.display_results(response, show_scores, show_json)\n",
    "    return response\n",
    "\n",
    "def explore_examples():\n",
    "    \"\"\"Show example queries with results\"\"\"\n",
    "    examples = [\n",
    "        \"quotes about hope by Oscar Wilde\",\n",
    "        \"inspirational quotes about success\",\n",
    "        \"quotes about love by Shakespeare\",\n",
    "        \"motivational quotes for difficult times\",\n",
    "        \"funny quotes about life\"\n",
    "    ]\n",
    "    \n",
    "    display(HTML(\"<h2>üìù Example Queries</h2>\"))\n",
    "    \n",
    "    for i, example in enumerate(examples, 1):\n",
    "        display(HTML(f\"\"\"\n",
    "        <div style=\"background-color: #f0f8ff; padding: 10px; margin: 5px 0; border-radius: 5px;\">\n",
    "            <strong>Example {i}:</strong> <code>search('{example}')</code>\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "    \n",
    "    display(HTML(\"\"\"\n",
    "    <div style=\"background-color: #fff9c4; padding: 15px; margin: 15px 0; border-radius: 8px;\">\n",
    "        <h4>üí° Tips:</h4>\n",
    "        <ul>\n",
    "            <li>Use <code>search(query)</code> for standard search</li>\n",
    "            <li>Use <code>search_with_ai(query)</code> for AI-enhanced analysis</li>\n",
    "            <li>Adjust <code>top_k</code> parameter to get more results</li>\n",
    "            <li>Set <code>show_json=True</code> to see the raw response data</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "\n",
    "def info():\n",
    "    \"\"\"Display information about the application\"\"\"\n",
    "    display(HTML(\"\"\"\n",
    "    <div style=\"border: 2px solid #2196F3; padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "        <h2>üìö Quotes RAG Application - Jupyter Notebook Version</h2>\n",
    "        <p><strong>Retrieval Augmented Generation for English Quotes with AI Enhancement</strong></p>\n",
    "        \n",
    "        <h3>üöÄ Getting Started:</h3>\n",
    "        <ol>\n",
    "            <li>Run <code>setup()</code> to load models and data</li>\n",
    "            <li>Use <code>search('your query')</code> to find quotes</li>\n",
    "            <li>Use <code>search_with_ai('your query')</code> for AI analysis</li>\n",
    "            <li>Try <code>explore_examples()</code> for sample queries</li>\n",
    "        </ol>\n",
    "        \n",
    "        <h3>üîß Available Functions:</h3>\n",
    "        <ul>\n",
    "            <li><code>setup()</code> - Initialize the application</li>\n",
    "            <li><code>search(query, top_k=5)</code> - Standard search</li>\n",
    "            <li><code>search_with_ai(query, top_k=5)</code> - AI-enhanced search</li>\n",
    "            <li><code>explore_examples()</code> - Show example queries</li>\n",
    "            <li><code>info()</code> - Display this information</li>\n",
    "        </ul>\n",
    "        \n",
    "        <h3>ü§ñ AI Features:</h3>\n",
    "        <ul>\n",
    "            <li>Uses DistilGPT-2 for quote analysis</li>\n",
    "            <li>Provides contextual insights</li>\n",
    "            <li>Identifies themes and patterns</li>\n",
    "            <li>Completely free and runs locally</li>\n",
    "        </ul>\n",
    "        \n",
    "        <h3>üì¶ Requirements:</h3>\n",
    "        <p>For AI features: <code>pip install transformers torch accelerate</code></p>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "\n",
    "# Display welcome message\n",
    "print(\"üéâ Quotes RAG Application loaded successfully!\")\n",
    "print(\"üìñ Run info() for detailed information\")\n",
    "print(\"üöÄ Run setup() to get started\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bab1482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TESTING COMPLETE RAG PIPELINE\n",
      "============================================================\n",
      "\n",
      "[TEST 1] Query: quotes about hope by Oscar Wilde\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753bed846f664427880fd531e35b19ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efb8354eba14f088c0ce452e8e7cf54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved 3 quotes\n",
      "üìù Summary: ü§ñ AI Analysis: 1.\n",
      "üéØ Best match: \"‚ÄúHearts are made to be broken.‚Äù...\" by Oscar Wilde,\n",
      "üìä Score: 0.9931\n",
      "\n",
      "[TEST 2] Query: inspirational quotes about success by famous authors\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef31177ac88e431893267087f2826af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea34e21c5f914592a06c2f2d759a1dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved 3 quotes\n",
      "üìù Summary: ü§ñ AI Analysis: 1.\n",
      "üéØ Best match: \"‚ÄúSuccess is stumbling from failure to failure with no loss of enthusiasm.‚Äù...\" by Winston S. Churchill\n",
      "üìä Score: 0.9898\n",
      "\n",
      "[TEST 3] Query: funny quotes about life and humor\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88287a7d3d84cbda1218fcc21337f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95be4e7cc16452fab4639aee2d22bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved 3 quotes\n",
      "üìù Summary: ü§ñ AI Analysis: 1.\n",
      "üéØ Best match: \"‚ÄúIt's hard to enjoy practical jokes when your whole life feels like one.‚Äù...\" by Rick Riordan,\n",
      "üìä Score: 0.9877\n",
      "\n",
      "[TEST 4] Query: quotes about love and relationships by Shakespeare\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7bf724afc74196a8439d12b918f100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55a0e0642cd46b494065769f05c0cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved 3 quotes\n",
      "üìù Summary: ü§ñ AI Analysis: 1.\n",
      "üéØ Best match: \"‚ÄúWords are easy, like the wind; Faithful friends are hard to find.‚Äù...\" by William Shakespeare,\n",
      "üìä Score: 0.9912\n",
      "\n",
      "[TEST 5] Query: motivational quotes for overcoming challenges\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9fc11389874b54899ab9388122e2f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1967621b79b47559c625f2feb1cf187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved 3 quotes\n",
      "üìù Summary: ü§ñ AI Analysis: 1.\n",
      "üéØ Best match: \"‚ÄúWhat you're supposed to do when you don't like a thing is change it. If you can't change it, change...\" by Maya Angelou,\n",
      "üìä Score: 0.9794\n",
      "\n",
      "[TEST 6] Query: quotes about wisdom and learning\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff60bc31c57430f8e7dfbee982817f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92aebaea83a47b6a399e0c541478f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved 3 quotes\n",
      "üìù Summary: ü§ñ AI Analysis: 1.\n",
      "üéØ Best match: \"‚ÄúWisdom comes from experience. Experience is often a result of lack of wisdom.‚Äù...\" by Terry Pratchett\n",
      "üìä Score: 0.9894\n",
      "\n",
      "[TEST 7] Query: quotes by women authors about strength\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc98ec8a5be4a6e81792b81c75c4e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db12526faf2b4c50ad9a596f490b4897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved 3 quotes\n",
      "üìù Summary: ü§ñ AI Analysis: 1.\n",
      "üéØ Best match: \"‚ÄúA brave man acknowledges the strength of others.‚Äù...\" by Veronica Roth,\n",
      "üìä Score: 0.9881\n",
      "\n",
      "[TEST 8] Query: quotes about friendship and loyalty\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d78ba4156f64e1dbbd8bac3a5fb0afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2335f9e5784ee386e5a6e5b1113068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved 3 quotes\n",
      "üìù Summary: ü§ñ AI Analysis: 1.\n",
      "üéØ Best match: \"‚ÄúThere is no friend as loyal as a book.‚Äù...\" by Ernest Hemingway\n",
      "üìä Score: 0.9901\n",
      "\n",
      "[TEST 9] Query: quotes about time and life philosophy\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ffb7a3292c64faf9b0ffe45c14541a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623fdf524f984fcd8e6ee19471de78d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved 3 quotes\n",
      "üìù Summary: ü§ñ AI Analysis: 1.\n",
      "üéØ Best match: \"‚ÄúYou have power over your mind - not outside events. Realize this, and you will find strength.‚Äù...\" by Marcus Aurelius,\n",
      "üìä Score: 0.9904\n",
      "\n",
      "[TEST 10] Query: quotes about dreams and aspirations\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8403bdda6eb5443380756488da30ac84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b620d5b72c24da6b69791a47400466d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved 3 quotes\n",
      "üìù Summary: ü§ñ AI Analysis: 1.\n",
      "üéØ Best match: \"‚ÄúDare to live the life you have dreamed for yourself. Go forward and make your dreams come true.‚Äù...\" by Ralph Waldo Emerson\n",
      "üìä Score: 0.9875\n",
      "\n",
      "============================================================\n",
      "üìä PIPELINE PERFORMANCE SUMMARY\n",
      "============================================================\n",
      "‚úÖ Successful queries: 10/10 (100.0%)\n",
      "üìà Average results per query: 3.0\n",
      "üéØ Average best match score: 0.9887\n",
      "\n",
      "============================================================\n",
      "üéâ RAG QUOTES APPLICATION SETUP COMPLETE!\n",
      "============================================================\n",
      "\n",
      "üìÅ Files created:\n",
      "‚Ä¢ fine_tuned_quotes_model/ - Fine-tuned sentence transformer\n",
      "‚Ä¢ quotes_index.faiss - FAISS vector index\n",
      "‚Ä¢ quotes_data.pkl - Processed quotes dataset\n",
      "‚Ä¢ streamlit_app.py - Streamlit web application\n",
      "\n",
      "üöÄ Next steps:\n",
      "1. Run 'streamlit run streamlit_app.py' to start the web app\n",
      "2. Test different query types in the interface\n",
      "3. Customize the model or add more sophisticated LLM integration\n",
      "4. Deploy to cloud platforms like Streamlit Cloud, Heroku, or AWS\n",
      "\n",
      "üìä System ready with 2507 quotes indexed and searchable!\n"
     ]
    }
   ],
   "source": [
    "# Test Complete Pipeline\n",
    "\n",
    "def test_complete_pipeline():\n",
    "    \"\"\"Test the complete RAG pipeline with various queries\"\"\"\n",
    "    \n",
    "    test_queries = [\n",
    "        \"quotes about hope by Oscar Wilde\",\n",
    "        \"inspirational quotes about success by famous authors\",\n",
    "        \"funny quotes about life and humor\",\n",
    "        \"quotes about love and relationships by Shakespeare\",\n",
    "        \"motivational quotes for overcoming challenges\",\n",
    "        \"quotes about wisdom and learning\",\n",
    "        \"quotes by women authors about strength\",\n",
    "        \"quotes about friendship and loyalty\",\n",
    "        \"quotes about time and life philosophy\",\n",
    "        \"quotes about dreams and aspirations\"\n",
    "    ]\n",
    "    \n",
    "    print(\"üß™ TESTING COMPLETE RAG PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results_summary = []\n",
    "    \n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"\\n[TEST {i}] Query: {query}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            # Test retrieval\n",
    "            retrieved = vector_index.search(query, top_k=3)\n",
    "            \n",
    "            # Test RAG response\n",
    "            rag_response = rag_pipeline.search_and_generate(query, top_k=3)\n",
    "            \n",
    "            print(f\"‚úÖ Retrieved {len(retrieved)} quotes\")\n",
    "            print(f\"üìù Summary: {rag_response['summary']}\")\n",
    "            \n",
    "            if retrieved:\n",
    "                best_match = retrieved[0]\n",
    "                print(f\"üéØ Best match: \\\"{best_match['quote'][:100]}...\\\" by {best_match['author']}\")\n",
    "                print(f\"üìä Score: {best_match['similarity_score']:.4f}\")\n",
    "            \n",
    "            results_summary.append({\n",
    "                'query': query,\n",
    "                'num_results': len(retrieved),\n",
    "                'best_score': retrieved[0]['similarity_score'] if retrieved else 0,\n",
    "                'has_results': len(retrieved) > 0\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            results_summary.append({\n",
    "                'query': query,\n",
    "                'num_results': 0,\n",
    "                'best_score': 0,\n",
    "                'has_results': False,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"üìä PIPELINE PERFORMANCE SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    successful_queries = sum(1 for r in results_summary if r['has_results'])\n",
    "    avg_results = np.mean([r['num_results'] for r in results_summary])\n",
    "    avg_score = np.mean([r['best_score'] for r in results_summary if r['best_score'] > 0])\n",
    "    \n",
    "    print(f\"‚úÖ Successful queries: {successful_queries}/{len(test_queries)} ({successful_queries/len(test_queries)*100:.1f}%)\")\n",
    "    print(f\"üìà Average results per query: {avg_results:.1f}\")\n",
    "    print(f\"üéØ Average best match score: {avg_score:.4f}\")\n",
    "    \n",
    "    return results_summary\n",
    "\n",
    "# Run complete pipeline test\n",
    "test_results = test_complete_pipeline()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üéâ RAG QUOTES APPLICATION SETUP COMPLETE!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"\\nüìÅ Files created:\")\n",
    "print(\"‚Ä¢ fine_tuned_quotes_model/ - Fine-tuned sentence transformer\")\n",
    "print(\"‚Ä¢ quotes_index.faiss - FAISS vector index\")  \n",
    "print(\"‚Ä¢ quotes_data.pkl - Processed quotes dataset\")\n",
    "print(\"‚Ä¢ streamlit_app.py - Streamlit web application\")\n",
    "\n",
    "print(f\"\\nüöÄ Next steps:\")\n",
    "print(\"1. Run 'streamlit run streamlit_app.py' to start the web app\")\n",
    "print(\"2. Test different query types in the interface\")\n",
    "print(\"3. Customize the model or add more sophisticated LLM integration\")\n",
    "print(\"4. Deploy to cloud platforms like Streamlit Cloud, Heroku, or AWS\")\n",
    "\n",
    "print(f\"\\nüìä System ready with {len(df_processed)} quotes indexed and searchable!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3fe2933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run streamlit_app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08649f43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
